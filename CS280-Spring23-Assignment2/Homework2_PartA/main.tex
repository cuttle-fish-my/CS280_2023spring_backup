\documentclass[12pt]{article}%
\usepackage{amsfonts}
\usepackage{fancyhdr}
\usepackage{comment}
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2.2cm, right=2.2cm]%
{geometry}
\usepackage{times}
\usepackage{amsmath}
\usepackage{changepage}
\usepackage{amssymb}
\usepackage{graphicx}%
\setcounter{MaxMatrixCols}{30}
\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\textbf{#1.} }{\ \rule{0.5em}{0.5em}}

\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}

\begin{document}

    \title{CS280 Spring 2023 Assignment 2 \\ Part A}
    \author{Convolutional Neural Network}
    \maketitle

    \paragraph{Name: Bingnan Li}

    \paragraph{Student ID: 2020533092}

    \newpage


    \subsubsection*{1. Convolution Cost (10 points)}
    Assume an input of shape  $c_i\times h\times w$  and a convolution kernel of shape  $c_o\times c_i\times k_h\times k_w$ , padding of  $(p_h,p_w)$ , and stride of  $(s_h,s_w)$ .
    \begin{itemize}
        \item What is the computational cost (multiplications and additions) for the forward propagation?\\
        {\bf Solution:}
        \par The output size has the formula as follows:
        \[c_{out}=\#\{kernels\}\]
        \[h_{out}=\left\lfloor\frac{h_{in}+2\times padding\_size_h-(kernel\_size_h-1)-1}{stride\_size_h}+1\right\rfloor \]
        \[w_{out}=\left\lfloor\frac{w_{in}+2\times padding\_size_w-(kernel\_size_w-1)-1}{stride\_size_w}+1\right\rfloor \]
        Substitute $h_{in}, w_{in}, padding\_size_h, padding\_size_w, stride\_size_h, stride\_size_w, kernel\_size_h$ and $kernel\_size_w$
        with $h, w, p_h,p_w,s_h,s_w,k_h$ and $k_w$ respectively, the output size is
        \[c_{out}=c_0\]
        \[h_{out}=\left\lfloor\frac{h+2p_h-k_h}{s_h}+1\right\rfloor \]
        \[w_{out}=\left\lfloor\frac{w+2p_w-k_w}{s_w}+1\right\rfloor \]

        Then for each element in output, it is calculated by $c_i\times k_h\times k_w$ times multiplications and $c_i\times k_h\times k_w - 1$ times additions.
        Thus, the computational cost is
        \[cost = c_0\left\lfloor\frac{h+2p_h-k_h}{s_h}+1\right\rfloor\left\lfloor\frac{w+2p_w-k_w}{s_w}+1\right\rfloor\left(2c_i k_h k_w-1\right)\]
        \item What is the memory footprint?
    \end{itemize}

    \newpage


    \subsubsection*{2. Convolution Kernel (10 points)}
    Assume there are two convolution kernels of size
    $k_1$ and $k_2$ respectively (with no nonlinear activation function in-between).
    \begin{itemize}
        \item Prove that the results of the two convolution operations can be expressed by a single convolution operation.
        \item What is the dimensionality of the equivalent single convolution?
        \item Is the converse true, i.e.,
        Can a convolution operation be decomposed into two smaller convolution operations?
    \end{itemize}


\end{document}